%pip install genai
%pip install pydub
%pip install requests

import os
import json
from google import genai
from google.colab import userdata

GEMINI_API_KEY=userdata.get('GEMINI_API_KEY')
SILICONFLOW_API_KEY=userdata.get('SILICONFLOW_API_KEY')

client = genai.Client(
  api_key=GEMINI_API_KEY
)

TTS_API_CONFIG = {
    "url": "https://api.siliconflow.cn/v1/audio/speech",
    "token": SILICONFLOW_API_KEY,  
    "default_params": {
        "response_format": "mp3",
        "sample_rate": 32000,
        "stream": False, 
        "speed": 1.1,
        "gain": 0,
        "model": "FunAudioLLM/CosyVoice2-0.5B",
        "voice": "FunAudioLLM/CosyVoice2-0.5B:alex"
    }
}

import json

file_url = "./test.mp4"

prompt = """
- å¸®æˆ‘ä»è¿™ä¸ªè§†é¢‘å½“ä¸­æå–å‡ºæ¥ 5-15 ä¸ªç‰‡æ®µï¼Œ
- è¿™äº›ç‰‡æ®µä¼šæ ¹æ®ä¸‹é¢çš„æè¿°æ¥é‡æ–°è¡¨è¾¾åˆé€‚çš„è§†é¢‘æ—¶é—´åºåˆ—ç»„åˆï¼Œæ–¹ä¾¿åç»­è¿›è¡Œè§†é¢‘çš„é‡æ–°æ‹¼æ¥ã€‚

- æ¯ä¸ªç‰‡æ®µçš„å¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´ï¼Œ
- è§†é¢‘æ‹¼æ¥è¦æœ‰ç½‘æ„Ÿï¼Œä¸è¦å‡ºç°é‡å¤çš„ç‰‡æ®µï¼Œ
- è¿™äº›ç‰‡æ®µèƒ½ç»„åˆå‡ºæ¥ä¸€ä¸ªé€‚åˆæ¨å¹¿æˆ·å¤–ç©ºè°ƒçš„å£æ’­è§†é¢‘ï¼Œæ€»æ—¶é—´é•¿åº¦åœ¨ 15-30s æœ€ä½³ã€‚

è¯·è¿”å› json æ ¼å¼æ•°æ®ï¼Œæ•°æ®æ ¼å¼é‡Œé™¤äº†åŒ…å«å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼Œ
å¼€å§‹æ—¶é—´ç”¨ start_time è¡¨ç¤ºï¼Œç»“æŸæ—¶é—´ç”¨ end_time è¡¨ç¤ºï¼Œ
æ•°æ®ç»“æ„å¦‚ä¸‹ï¼š
{
  "total_duration_estimate": "28s",
  "clip_count": 8,
  "clips": [
    {
      "clip_id": 1,
      "start_time": "00:00",
      "end_time": "00:04",
      "visual_description": "ã€çƒ­åˆ°èåŒ–ã€‘ç‰¹å†™å¤æ—¥æˆ·å¤–çƒˆæ—¥ç‚ç‚ï¼Œäººä»¬æ±—æµæµƒèƒŒï¼Œè¡¨æƒ…ç—›è‹¦æŒ£æ‰ï¼Œç”šè‡³å‡ºç°å¤¸å¼ çš„â€œè’¸å‘â€æ•ˆæœã€‚ç½‘æ„Ÿï¼šâ€˜è¿™å¤©æ°”ï¼Œå‡ºé—¨å°±æ˜¯é“æ¿çƒ§ï¼â€™"
    },
    ...
  ]
}
"""


response = client.models.generate_content(
    model="gemini-2.5-pro",
    contents=[
      file_url,
      prompt
    ]
)

original_text = response.text

json_data = original_text.split("```json")[1].split("```")[0]
video_chunk_data = json.loads(json_data)

print(json.dumps(video_chunk_data, indent=2, ensure_ascii=False))

import subprocess

def time_to_seconds(time_str):
    """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’æ•° (æ”¯æŒ MM:SS å’Œ MM:SS.mmm æ ¼å¼)"""
    if ':' not in time_str:
        return float(time_str)

    parts = time_str.split(':')
    if len(parts) == 2:  
        minutes = int(parts[0])
        seconds = float(parts[1])
        return minutes * 60 + seconds
    elif len(parts) == 3:  
        hours = int(parts[0])
        minutes = int(parts[1])
        seconds = float(parts[2])
        return hours * 3600 + minutes * 60 + seconds
    else:
        return float(time_str)

def extract_segment_with_audio(video_path, start_time, end_time, output_path, trim_seconds=0.1):
    """
    ä½¿ç”¨ffmpegæå–è§†é¢‘ç‰‡æ®µï¼ˆåŒ…å«éŸ³é¢‘ï¼‰ï¼Œå¹¶å¯é€‰æ‹©è£åˆ‡é¦–å°¾
    trim_seconds: ä»å¼€å¤´å’Œç»“å°¾å„è£åˆ‡çš„ç§’æ•°ï¼Œæœ‰åŠ©äºæ¶ˆé™¤æ‹¼æ¥æ—¶çš„åœé¡¿æ„Ÿ
    """
    actual_start = start_time + trim_seconds
    actual_end = end_time - trim_seconds

    if actual_end <= actual_start:
        print(f"è­¦å‘Š: ç‰‡æ®µå¤ªçŸ­ï¼Œæ— æ³•è£åˆ‡ {trim_seconds}sï¼Œä½¿ç”¨åŸå§‹æ—¶é—´")
        actual_start = start_time
        actual_end = end_time

    duration = actual_end - actual_start

    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-ss', str(actual_start),
        '-t', str(duration),
        '-c:v', 'libx264',     
        '-c:a', 'aac',         
        '-r', '25',           
        '-preset', 'fast',      
        '-crf', '23',           
        '-avoid_negative_ts', 'make_zero',
        '-fflags', '+genpts',   
        '-y',
        output_path
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"æå–ç‰‡æ®µæˆåŠŸ: {output_path} (è£åˆ‡äº† {trim_seconds}s)")
        return True
    except subprocess.CalledProcessError as e:
        print(f"ffmpegé”™è¯¯: {e.stderr}")
        return False
    except FileNotFoundError:
        print("é”™è¯¯: æ‰¾ä¸åˆ°ffmpegï¼Œè¯·å…ˆå®‰è£…ffmpeg")
        return False

def convert_to_vertical_simple(input_path, output_path, target_size=(1080, 1920)):
    """ä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³•è½¬æ¢ä¸ºç«–å±"""
    target_width, target_height = target_size

    cmd = [
        'ffmpeg',
        '-i', input_path,
        '-vf', f"scale={target_width}:{target_height}:force_original_aspect_ratio=decrease,pad={target_width}:{target_height}:(ow-iw)/2:(oh-ih)/2",
        '-c:a', 'copy',
        '-y',
        output_path
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"è½¬æ¢ç«–å±æˆåŠŸ (ç®€å•æ¨¡å¼): {output_path}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"ffmpegç®€å•æ¨¡å¼ä¹Ÿå¤±è´¥: {e.stderr}")
        return False

def convert_to_vertical_ffmpeg(input_path, output_path, target_size=(1080, 1920), bg_color=(0, 0, 0)):
    """ä½¿ç”¨ffmpegå°†æ¨ªå±è§†é¢‘è½¬æ¢ä¸ºç«–å±"""
    target_width, target_height = target_size

    filter_complex = f"scale='min({target_width},iw)':'min({target_height},ih)':force_original_aspect_ratio=decrease,pad={target_width}:{target_height}:(ow-iw)/2:(oh-ih)/2:black"

    cmd = [
        'ffmpeg',
        '-i', input_path,
        '-vf', filter_complex,
        '-c:a', 'copy',  
        '-y',
        output_path
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"è½¬æ¢ç«–å±æˆåŠŸ: {output_path}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"ffmpegé”™è¯¯: {e.stderr}")
        return convert_to_vertical_simple(input_path, output_path, target_size)

def concatenate_videos_with_transitions(video_paths, output_path, use_crossfade=False):
    """
    ä½¿ç”¨ffmpegæ‹¼æ¥è§†é¢‘ï¼Œæ·»åŠ è½¬åœºæ•ˆæœå‡å°‘åœé¡¿æ„Ÿ
    use_crossfade: æ˜¯å¦ä½¿ç”¨äº¤å‰æ·¡åŒ–è½¬åœº
    """
    list_file = "video_list.txt"
    with open(list_file, 'w', encoding='utf-8') as f:
        for path in video_paths:
            f.write(f"file '{os.path.abspath(path)}'\n")

    cmd = [
        'ffmpeg',
        '-f', 'concat',
        '-safe', '0',
        '-i', list_file,
        '-c:v', 'libx264',     
        '-c:a', 'aac',
        '-r', '25',             
        '-preset', 'fast',
        '-crf', '23',
        '-fflags', '+genpts',  
        '-y',
        output_path
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"è§†é¢‘æ‹¼æ¥æˆåŠŸ: {output_path}")
        if os.path.exists(list_file):
            os.remove(list_file)
        return True
    except subprocess.CalledProcessError as e:
        print(f"ffmpegé”™è¯¯: {e.stderr}")
        if os.path.exists(list_file):
            os.remove(list_file)
        return False


def process_video_only(video_path, video_chunk_data, output_path, target_size=(1080, 1920), trim_seconds=0.1):
    """
    åªå¤„ç†è§†é¢‘éƒ¨åˆ†ï¼Œä¸å¤„ç†éŸ³é¢‘
    """
    clips = video_chunk_data['clips']

    temp_dir = "temp_processing"
    os.makedirs(temp_dir, exist_ok=True)

    processed_video_paths = []

    print(f"ğŸ¬ å¼€å§‹å¤„ç† {len(clips)} ä¸ªè§†é¢‘ç‰‡æ®µ...")

    try:
        for i, clip in enumerate(clips):
            clip_id = clip['clip_id']
            start_time = time_to_seconds(clip['start_time'])
            end_time = time_to_seconds(clip['end_time'])

            print(f"\n--- å¤„ç†ç‰‡æ®µ {clip_id}/{len(clips)} ---")
            print(f"æ—¶é—´: {start_time}s - {end_time}s")
            print(f"ç”»é¢: {clip['visual_description']}")

            segment_path = os.path.join(temp_dir, f"segment_{clip_id}.mp4")
            if not extract_segment_with_audio(video_path, start_time, end_time, segment_path, trim_seconds):
                print(f"è·³è¿‡ç‰‡æ®µ {clip_id}: æå–å¤±è´¥")
                continue

            vertical_path = os.path.join(temp_dir, f"vertical_{clip_id}.mp4")
            if not convert_to_vertical_ffmpeg(segment_path, vertical_path, target_size):
                print(f"è·³è¿‡ç‰‡æ®µ {clip_id}: ç«–å±è½¬æ¢å¤±è´¥")
                continue

            processed_video_paths.append(vertical_path)

        if not processed_video_paths:
            raise ValueError("æ²¡æœ‰æˆåŠŸå¤„ç†çš„è§†é¢‘ç‰‡æ®µ")

        print(f"\nğŸ¬ æ‹¼æ¥ {len(processed_video_paths)} ä¸ªç‰‡æ®µ...")
        if not concatenate_videos_with_transitions(processed_video_paths, output_path, use_crossfade=False):
            raise ValueError("è§†é¢‘æ‹¼æ¥å¤±è´¥")

        print(f"\nâœ… è§†é¢‘å¤„ç†å®Œæˆ!")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")

        return True

    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

    finally:
        print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        if os.path.exists(temp_dir):
            for file in os.listdir(temp_dir):
                file_path = os.path.join(temp_dir, file)
                try:
                    os.remove(file_path)
                except Exception as e:
                    print(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

            try:
                os.rmdir(temp_dir)
            except Exception as e:
                print(f"æ¸…ç†ç›®å½•å¤±è´¥: {e}")

#åŠŸèƒ½ä»£ç ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
import requests
from pydub import AudioSegment

def generate_voiceover_script_with_gemini(video_path):
    """
    ä½¿ç”¨Geminiç”Ÿæˆé…éŸ³æ–‡æ¡ˆ
    åŸºäºæ–°åˆæˆçš„è§†é¢‘å†…å®¹é…åˆ Prompt ç”Ÿæˆè¦æ±‚çš„æ–‡æ¡ˆ
    """

    prompt = """
    å¸®æˆ‘åŸºäºå½“å‰çš„è§†é¢‘æ¥ç”Ÿæˆä¸€ä»½é€‚åˆçš„å£æ’­å¸¦è´§æ–‡æ¡ˆï¼Œæ ¸å¿ƒè¦çªå‡ºæˆ·å¤–ç©ºè°ƒçš„å–ç‚¹ï¼Œ
    è¦æ±‚æ—¶é—´åŒ¹é…è¦æ¸…æ™°ï¼Œæ–‡æ¡ˆç®€çŸ­æœ‰åŠ›ã€‚
    æ¯ç§’æœ€é•¿èƒ½è¯» 4 ä¸ªå­—å·¦å³ï¼ŒæŒ‰ç…§è¿™ä¸ªæ¥å‚è€ƒæ–‡æ¡ˆé•¿åº¦ã€‚
    è¿”å› json æ ¼å¼ï¼ŒåŒ…å«æ¯ä¸ªæ—¶é—´æ®µçš„æ–‡æ¡ˆå’Œå¯¹åº”çš„æ—¶é—´æˆ³ã€‚
    æ ¼å¼å¦‚ï¼š{'segments': [{'start_time': '00:00', 'end_time': '00:02', 'script': 'æ–‡æ¡ˆå†…å®¹'}]}
    """
    print("ğŸ¤– æ­£åœ¨ä½¿ç”¨Geminiç”Ÿæˆé…éŸ³æ–‡æ¡ˆ...")

    response = client.models.generate_content(
        model="gemini-2.5-pro",
        contents=[
            video_path,
            prompt
        ]
    )

    print("âœ… Geminiæ–‡æ¡ˆç”Ÿæˆå®Œæˆ")
    return response.text

def extract_gemini_script(gemini_response):
    """ä»Geminiå“åº”ä¸­æå–JSONæ ¼å¼çš„æ–‡æ¡ˆ"""
    try:
        if "```json" in gemini_response and "```" in gemini_response:
            json_data = gemini_response.split("```json")[1].split("```")[0]
            script_data = json.loads(json_data)
            print("âœ… æ–‡æ¡ˆæ•°æ®è§£ææˆåŠŸ")
            return script_data
        else:
            print("âŒ æœªæ‰¾åˆ°JSONæ ¼å¼çš„æ–‡æ¡ˆæ•°æ®")
            return None
    except Exception as e:
        print(f"âŒ æ–‡æ¡ˆæ•°æ®è§£æå¤±è´¥: {e}")
        return None

def generate_tts_audio(text, output_path, clip_id=None):
    """è°ƒç”¨TTS APIç”Ÿæˆè¯­éŸ³"""
    try:
        headers = {
            "Authorization": f"Bearer {TTS_API_CONFIG['token']}",
            "Content-Type": "application/json"
        }

        payload = {
            "input": text,
            **TTS_API_CONFIG["default_params"]
        }

        print(f"æ­£åœ¨ç”Ÿæˆè¯­éŸ³ clip_{clip_id}: {text[:50]}...")

        response = requests.post(
            TTS_API_CONFIG["url"],
            json=payload,
            headers=headers,
            timeout=30
        )

        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)
            print(f"âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸ: {output_path}")
            return True
        else:
            print(f"âŒ TTS APIé”™è¯¯ clip_{clip_id}: {response.status_code} - {response.text}")
            return False

    except Exception as e:
        print(f"âŒ è¯­éŸ³ç”Ÿæˆå¼‚å¸¸ clip_{clip_id}: {e}")
        return False

def replace_audio_in_video(video_path, audio_path, output_path):
    """æ›¿æ¢è§†é¢‘ä¸­çš„éŸ³é¢‘"""
    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-i', audio_path,
        '-c:v', 'copy',  # è§†é¢‘ä¸é‡æ–°ç¼–ç 
        '-c:a', 'aac',   # éŸ³é¢‘ç¼–ç ä¸ºAAC
        '-map', '0:v:0', # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å…¥çš„è§†é¢‘æµ
        '-map', '1:a:0', # ä½¿ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„éŸ³é¢‘æµ
        '-shortest',     # ä»¥è¾ƒçŸ­çš„æµä¸ºå‡†
        '-y',
        output_path
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"éŸ³é¢‘æ›¿æ¢æˆåŠŸ: {output_path}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"ffmpegé”™è¯¯: {e.stderr}")
        return False


def generate_audio_from_script_and_merge(video_path, script_data, output_path, audio_dir="./script_audio"):
    """æ ¹æ®æ–‡æ¡ˆç”ŸæˆéŸ³é¢‘å¹¶åˆæˆåˆ°è§†é¢‘"""
    os.makedirs(audio_dir, exist_ok=True)

    if not script_data or 'segments' not in script_data:
        print("âŒ æ— æ•ˆçš„æ–‡æ¡ˆæ•°æ®")
        return False

    segments = script_data['segments']
    audio_files = []

    print(f"ğŸµ å¼€å§‹ç”Ÿæˆ {len(segments)} ä¸ªæ–‡æ¡ˆéŸ³é¢‘...")

    for i, segment in enumerate(segments):
        script_text = segment['script']
        audio_filename = f"script_{i+1}.mp3"
        audio_path = os.path.join(audio_dir, audio_filename)

        if generate_tts_audio(script_text, audio_path, f"script_{i+1}"):
            audio_files.append(audio_path)
        else:
            start_time = time_to_seconds(segment['start_time'])
            end_time = time_to_seconds(segment['end_time'])
            duration = end_time - start_time

            silence = AudioSegment.silent(duration=int(duration * 1000))
            silence_path = os.path.join(audio_dir, f"silence_{i+1}.wav")
            silence.export(silence_path, format="wav")
            audio_files.append(silence_path)

    if not audio_files:
        print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶")
        return False

    print("ğŸµ æ‹¼æ¥éŸ³é¢‘æ–‡ä»¶...")
    combined_audio = AudioSegment.empty()
    for audio_file in audio_files:
        try:
            if audio_file.endswith('.mp3'):
                audio_segment = AudioSegment.from_mp3(audio_file)
            else:
                audio_segment = AudioSegment.from_wav(audio_file)
            combined_audio += audio_segment
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥ {audio_file}: {e}")

    combined_audio_path = os.path.join(audio_dir, "combined_script_audio.wav")
    combined_audio.export(combined_audio_path, format="wav")
    print(f"âœ… éŸ³é¢‘æ‹¼æ¥å®Œæˆ: {combined_audio_path}")

    print("ğŸ¬ å°†éŸ³é¢‘åˆæˆåˆ°è§†é¢‘...")
    if replace_audio_in_video(video_path, combined_audio_path, output_path):
        print(f"âœ… æœ€ç»ˆè§†é¢‘ç”Ÿæˆå®Œæˆ: {output_path}")
        return True
    else:
        print("âŒ éŸ³é¢‘åˆæˆå¤±è´¥")
        return False

from datetime import datetime

input_video_path = "./test.mp4"
temp_video_path = f"./temp_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
output_video_path = f"./final_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"

target_size = (1080, 1920)  


# ç¬¬ä¸€é˜¶æ®µï¼šåªå¤„ç†è§†é¢‘ï¼Œä¸å¤„ç†éŸ³é¢‘
video_success = process_video_only(
    video_path=input_video_path,
    video_chunk_data=video_chunk_data,
    output_path=temp_video_path,
    target_size=target_size,
    trim_seconds=0.2
)

# ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨Geminiç”Ÿæˆæ–‡æ¡ˆ
gemini_response = generate_voiceover_script_with_gemini(temp_video_path)

# è§£ææ–‡æ¡ˆ
script_data = extract_gemini_script(gemini_response)

if script_data:
    print("\n" + "="*60)
    print("ğŸµ ç¬¬ä¸‰é˜¶æ®µï¼šç”Ÿæˆé…éŸ³å¹¶åˆæˆ...")
    print("="*60)

    # ç¬¬ä¸‰é˜¶æ®µï¼šæ ¹æ®æ–‡æ¡ˆç”ŸæˆéŸ³é¢‘å¹¶åˆæˆ
    final_success = generate_audio_from_script_and_merge(
        video_path=temp_video_path,
        script_data=script_data,
        output_path=output_video_path,
        audio_dir="./script_audio"
    )

    if final_success:
        if os.path.exists(temp_video_path):
            os.remove(temp_video_path)
            print(f"âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_video_path}")

        script_file = f"script_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(script_file, 'w', encoding='utf-8') as f:
            json.dump(script_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“„ æ–‡æ¡ˆä¿¡æ¯å·²ä¿å­˜: {script_file}")

        info_file = f"video_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(video_chunk_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ é¡¹ç›®ä¿¡æ¯å·²ä¿å­˜: {info_file}")

    else:
        print("âŒ é…éŸ³åˆæˆå¤±è´¥ï¼Œä½†è§†é¢‘æ–‡ä»¶å·²ç”Ÿæˆ:", temp_video_path)
        output_video_path = temp_video_path  
else:
    print("âŒ æ–‡æ¡ˆè§£æå¤±è´¥ï¼Œä½†è§†é¢‘æ–‡ä»¶å·²ç”Ÿæˆ:", temp_video_path)
    output_video_path = temp_video_path  

print("\n" + "="*60)
print("ğŸ‰ å¤„ç†å®Œæˆï¼")
print("="*60)